_target_: pdp.workspace.DiffusionPolicyWorkspace

dataset:
    _target_: pdp.dataset.dataset.DiffusionPolicyDataset
    zarr_path: null # Set from command line
    horizon: 9
    pad_after: 0 # 7
    pad_before: 0 # 1

dataloader:
    batch_size: 512
    num_workers: 8
    persistent_workers: false
    pin_memory: true
    shuffle: true
    drop_last: true

val_dataloader:
    batch_size: 1024
    num_workers: 1
    persistent_workers: false
    pin_memory: true
    shuffle: false

ema:
    _target_: pdp.model.EMAModel
    inv_gamma: 1.0
    max_value: 0.9999
    min_value: 0.0
    power: 0.75
    update_after_step: 0

logging:
    group: null
    id: null
    mode: online
    name: null
    project: physdiffpol
    resume: true

optimizer:
    betas:
        - 0.9
        - 0.95
    lr: 0.0001
    weight_decay: 0.001

policy: # TODO
    _target_: pdp.policy.DiffusionPolicy
    num_inference_steps: 100
    pred_action_steps_only: true
    model:
        _target_: pdp.modules.TransformerForDiffusion
        obs_type: ref
        task: track
        causal_attn: True # (needed for the observation)
        past_action_visible: False # <------------------------------------- CHECK
        film_conditioning: True
        cond_dim: 360
        horizon: 4
        n_obs_steps: 4
        n_action_steps: 1
        input_dim: 69
        n_cond_layers: 10
        n_emb: 512 # BIG CHANGE
        n_head: 8
        n_layer: 10
        output_dim: 69
        p_drop_attn: 0.3 # .3
        p_drop_emb: 0.0 # 0.0
    noise_scheduler:
        _target_: diffusers.schedulers.scheduling_ddpm.DDPMScheduler
        beta_end: 0.02
        beta_schedule: squaredcos_cap_v2
        beta_start: 0.0001
        clip_sample: true
        num_train_timesteps: 100
        prediction_type: sample
        variance_type: fixed_small

training:
    save_checkpoint_every: 50
    topk:
        format_str: epoch={epoch:04d}-train_loss={train_loss:.3f}.ckpt
        k: 5
        mode: min
        monitor_key: train_loss
    debug: false
    data_upsampling: true
    device: cuda:0
    gradient_accumulate_every: 1
    lr_scheduler: cosine
    lr_warmup_steps: 1000
    max_train_steps: null
    max_val_steps: null
    num_epochs: 1500
    resume: true
    rollout_every: 25
    sample_every: 25
    seed: 42
    tqdm_interval_sec: 1.0
    use_ema: true
    val_every: 25
    logging: true
